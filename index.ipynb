{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we put our files in the cloned git so git can track it as we make changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#app name is just the name of the app\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mappName(\u001b[39m'\u001b[39;49m\u001b[39mmy_rheeza_practice\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mgetOrCreate() \u001b[39m#connection # creating an instance of connection\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/session.py:483\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m     session \u001b[39m=\u001b[39m SparkSession(sc, options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[1;32m    481\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     \u001b[39mgetattr\u001b[39m(\n\u001b[0;32m--> 483\u001b[0m         \u001b[39mgetattr\u001b[39;49m(session\u001b[39m.\u001b[39;49m_jvm, \u001b[39m\"\u001b[39;49m\u001b[39mSparkSession$\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39mMODULE$\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\u001b[39m.\u001b[39mapplyModifiableSettings(session\u001b[39m.\u001b[39m_jsparkSession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[1;32m    485\u001b[0m \u001b[39mreturn\u001b[39;00m session\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m UserHelpAutoCompletion\u001b[39m.\u001b[39mKEY:\n\u001b[1;32m   1710\u001b[0m     \u001b[39mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1712\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gateway_client\u001b[39m.\u001b[39;49msend_command(\n\u001b[1;32m   1713\u001b[0m     proto\u001b[39m.\u001b[39;49mREFLECTION_COMMAND_NAME \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1714\u001b[0m     proto\u001b[39m.\u001b[39;49mREFL_GET_UNKNOWN_SUB_COMMAND_NAME \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1715\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m proto\u001b[39m.\u001b[39;49mEND_COMMAND_PART)\n\u001b[1;32m   1716\u001b[0m \u001b[39mif\u001b[39;00m answer \u001b[39m==\u001b[39m proto\u001b[39m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1717\u001b[0m     \u001b[39mreturn\u001b[39;00m JavaPackage(name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gateway_client, jvm_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "#app name is just the name of the app\n",
    "spark = SparkSession.builder.appName('rheeza').getOrCreate() #connection # creating an instance of connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # can take multiline attribute, to remove an added column called corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = spark.read.json('dataset.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.show(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_json('dataset.json') # Just trying to observe the difference here spark vs pandas read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ageofparticipant: long (nullable = true)\n",
      " |-- clinician: struct (nullable = true)\n",
      " |    |-- branch: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- role: string (nullable = true)\n",
      " |-- drug_used: string (nullable = true)\n",
      " |-- experimentenddate: string (nullable = true)\n",
      " |-- experimentstartdate: string (nullable = true)\n",
      " |-- noofhourspassedatfirstreaction: long (nullable = true)\n",
      " |-- result: struct (nullable = true)\n",
      " |    |-- conclusion: string (nullable = true)\n",
      " |    |-- sideeffectsonparticipant: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the structure of the dataset, datatypes struct is nested, long is an integer type\n",
    "trials_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+---------+-----------------+-------------------+------------------------------+--------------------+\n",
      "|ageofparticipant|           clinician|drug_used|experimentenddate|experimentstartdate|noofhourspassedatfirstreaction|              result|\n",
      "+----------------+--------------------+---------+-----------------+-------------------+------------------------------+--------------------+\n",
      "|              19|{Ontario, Saul, t...|  Placebo|    1619827200000|      1617235200000|                            52|{BP normalized, r...|\n",
      "|              14|{Ontario, Saul, n...| Naproxen|    1619827200000|      1617235200000|                            78|    {Follow-up, N/A}|\n",
      "|              17|{Ontario, Saul, n...|  Placebo|    1619827200000|      1617235200000|                            14|    {Follow-up, N/A}|\n",
      "+----------------+--------------------+---------+-----------------+-------------------+------------------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.dtypes # data types in list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.columns # getting the name of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnull, count, isnan, when, col, date_format, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's flatten our json file so each attribute appears as a column\n",
    "# flatten is making all each attribute in json appear on an individual column--no nesting, e.g branch will not be under clinician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy way of doing this, split the columns\n",
    "columns = [\n",
    " 'ageofparticipant',\n",
    " 'clinician.branch',\n",
    " 'clinician.name',\n",
    " 'clinician.role',\n",
    " 'drug_used',\n",
    " 'experimentenddate',\n",
    " 'experimentstartdate',\n",
    " 'noofhourspassedatfirstreaction',\n",
    " 'result.conclusion',\n",
    " 'result.sideeffectsonparticipant'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+-------+---------+---------+-----------------+-------------------+------------------------------+-------------+------------------------+\n",
      "|ageofparticipant| branch|   name|     role|drug_used|experimentenddate|experimentstartdate|noofhourspassedatfirstreaction|   conclusion|sideeffectsonparticipant|\n",
      "+----------------+-------+-------+---------+---------+-----------------+-------------------+------------------------------+-------------+------------------------+\n",
      "|              19|Ontario|   Saul|therapist|  Placebo|    1619827200000|      1617235200000|                            52|BP normalized|          rashes on neck|\n",
      "|              14|Ontario|   Saul|    nurse| Naproxen|    1619827200000|      1617235200000|                            78|    Follow-up|                     N/A|\n",
      "|              17|Ontario|   Saul|    nurse|  Placebo|    1619827200000|      1617235200000|                            14|    Follow-up|                     N/A|\n",
      "|              18|Ontario|   Will|    nurse| Naproxen|    1619827200000|      1617235200000|                            14|BP normalized|                     N/A|\n",
      "|              17|Ontario|Patrick|   doctor| Naproxen|    1619827200000|      1617235200000|                            22|    No effect|          rashes on neck|\n",
      "|              17|Ontario|Patrick|   doctor| Naproxen|    1619827200000|      1617235200000|                             4|    Follow-up|               headaches|\n",
      "|              20|Ontario|   Saul|   doctor| Naproxen|    1619827200000|      1617235200000|                            85|    No effect|               headaches|\n",
      "|              15|Ontario|   Saul|   doctor|  Placebo|    1619827200000|      1617235200000|                            49|    No effect|          rashes on neck|\n",
      "|              14|Ontario|   Will|therapist|  Placebo|    1619827200000|      1617235200000|                            84|    Follow-up|               headaches|\n",
      "|              20|Ontario| Colins|    nurse|  Placebo|    1619827200000|      1617235200000|                            66|    Follow-up|           arms and feet|\n",
      "|              18|Ontario|Patrick|   doctor|  Placebo|    1619827200000|      1617235200000|                            40|BP normalized|             light fever|\n",
      "|              17|Ontario|Patrick|   doctor|  Placebo|    1619827200000|      1617235200000|                            72|BP normalized|           arms and feet|\n",
      "|              19|Ontario| Colins|therapist|  Placebo|    1619827200000|      1617235200000|                            36|    No effect|                     N/A|\n",
      "|              15|Ontario| Colins|therapist| Naproxen|    1619827200000|      1617235200000|                            12|BP normalized|               headaches|\n",
      "|              19|Ontario|   Saul|therapist|  Placebo|    1619827200000|      1617235200000|                            14|    No effect|                     N/A|\n",
      "|              16|Ontario| Colins|    nurse|  Placebo|    1619827200000|      1617235200000|                            63|BP normalized|                     N/A|\n",
      "|              16|Ontario|   Saul|    nurse| Naproxen|    1619827200000|      1617235200000|                            70|BP normalized|               headaches|\n",
      "|              18|Ontario|   Will|therapist| Naproxen|    1619827200000|      1617235200000|                            10|BP normalized|                     N/A|\n",
      "|              16|Ontario|Patrick|    nurse| Naproxen|    1619827200000|      1617235200000|                            11|    Follow-up|          rashes on neck|\n",
      "|              14|Ontario|Patrick|   doctor| Naproxen|    1619827200000|      1617235200000|                            32|    No effect|             light fever|\n",
      "+----------------+-------+-------+---------+---------+-----------------+-------------------+------------------------------+-------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials_df.select(columns).show() # This is just seeing the nested part - flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ageofparticipant: long (nullable = true)\n",
      " |-- clinician: struct (nullable = true)\n",
      " |    |-- branch: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- role: string (nullable = true)\n",
      " |-- drug_used: string (nullable = true)\n",
      " |-- experimentenddate: string (nullable = true)\n",
      " |-- experimentstartdate: string (nullable = true)\n",
      " |-- noofhourspassedatfirstreaction: long (nullable = true)\n",
      " |-- result: struct (nullable = true)\n",
      " |    |-- conclusion: string (nullable = true)\n",
      " |    |-- sideeffectsonparticipant: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing functions to count null value\n",
    "# import all the functions module of pyspark\n",
    "\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or simply import the needed functions\n",
    "from pyspark.sql.functions import isnull, count, isnan, when, col, date_format, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count all columns with null values, also create a condition to sieve --all columns\n",
    "# when is null pick column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# trials_df.select([ fn.count(fn.when(fn.col(column).isNull(), column)).alias(column) for column in columns]) # perform fn when isnull =\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# null_columns = trials_df.select([fn.count(fn.when(fn.col(c).isNull(), c)).alias(c) for c in trials_df.columns])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m null_columns \u001b[39m=\u001b[39m trials_df\u001b[39m.\u001b[39mselect([count(when(col(c)\u001b[39m.\u001b[39misNull(), c))\u001b[39m.\u001b[39malias(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m trials_df\u001b[39m.\u001b[39mcolumns])\n\u001b[1;32m      4\u001b[0m null_columns\u001b[39m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[154], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# trials_df.select([ fn.count(fn.when(fn.col(column).isNull(), column)).alias(column) for column in columns]) # perform fn when isnull =\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# null_columns = trials_df.select([fn.count(fn.when(fn.col(c).isNull(), c)).alias(c) for c in trials_df.columns])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m null_columns \u001b[39m=\u001b[39m trials_df\u001b[39m.\u001b[39mselect([count(when(col(c)\u001b[39m.\u001b[39misNull(), c))\u001b[39m.\u001b[39malias(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m trials_df\u001b[39m.\u001b[39mcolumns])\n\u001b[1;32m      4\u001b[0m null_columns\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/utils.py:160\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(functions, f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/functions.py:221\u001b[0m, in \u001b[0;36mcol\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m@try_remote_functions\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcol\u001b[39m(col: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Column:\n\u001b[1;32m    196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    Returns a :class:`~pyspark.sql.Column` based on the given column name.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m    Column<'x'>\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mreturn\u001b[39;00m _invoke_function(\u001b[39m\"\u001b[39;49m\u001b[39mcol\u001b[39;49m\u001b[39m\"\u001b[39;49m, col)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/functions.py:94\u001b[0m, in \u001b[0;36m_invoke_function\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mInvokes JVM function identified by name with args\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mand wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39massert\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m jf \u001b[39m=\u001b[39m _get_jvm_function(name, SparkContext\u001b[39m.\u001b[39;49m_active_spark_context)\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m Column(jf(\u001b[39m*\u001b[39margs))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/functions.py:85\u001b[0m, in \u001b[0;36m_get_jvm_function\u001b[0;34m(name, sc)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mRetrieves JVM function identified by name from\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39mJava gateway associated with sc.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39massert\u001b[39;00m sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mfunctions, name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m UserHelpAutoCompletion\u001b[39m.\u001b[39mKEY:\n\u001b[1;32m   1710\u001b[0m     \u001b[39mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1712\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gateway_client\u001b[39m.\u001b[39;49msend_command(\n\u001b[1;32m   1713\u001b[0m     proto\u001b[39m.\u001b[39;49mREFLECTION_COMMAND_NAME \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1714\u001b[0m     proto\u001b[39m.\u001b[39;49mREFL_GET_UNKNOWN_SUB_COMMAND_NAME \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1715\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m proto\u001b[39m.\u001b[39;49mEND_COMMAND_PART)\n\u001b[1;32m   1716\u001b[0m \u001b[39mif\u001b[39;00m answer \u001b[39m==\u001b[39m proto\u001b[39m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1717\u001b[0m     \u001b[39mreturn\u001b[39;00m JavaPackage(name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gateway_client, jvm_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "# trials_df.select([ fn.count(fn.when(fn.col(column).isNull(), column)).alias(column) for column in columns]) # perform fn when isnull =\n",
    "# null_columns = trials_df.select([fn.count(fn.when(fn.col(c).isNull(), c)).alias(c) for c in trials_df.columns])\n",
    "null_columns = trials_df.select([count(when(col(c).isNull(), c)).alias(c) for c in trials_df.columns])\n",
    "null_columns.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting null values per column\n",
    "# Only when that column is null\n",
    "# nulls_df = trials_df.select([fn.count(fn.when(fn.col(c).isNull(), c)).alias(c) for c in columns])\n",
    "# nulls_df.show()\n",
    "# Throwing error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "-flatten df\n",
    "-address null values\n",
    "-rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the rows again in flattened format\n",
    "\n",
    "new_trials_df = trials_df.select([*columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ageofparticipant: long (nullable = true)\n",
      " |-- branch: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- role: string (nullable = true)\n",
      " |-- drug_used: string (nullable = true)\n",
      " |-- experimentenddate: string (nullable = true)\n",
      " |-- experimentstartdate: string (nullable = true)\n",
      " |-- noofhourspassedatfirstreaction: long (nullable = true)\n",
      " |-- conclusion: string (nullable = true)\n",
      " |-- sideeffectsonparticipant: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ageofparticipant',\n",
       " 'branch',\n",
       " 'name',\n",
       " 'role',\n",
       " 'drug_used',\n",
       " 'experimentenddate',\n",
       " 'experimentstartdate',\n",
       " 'noofhourspassedatfirstreaction',\n",
       " 'conclusion',\n",
       " 'sideeffectsonparticipant']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ageofparticipant',\n",
       " 'branch',\n",
       " 'name',\n",
       " 'role',\n",
       " 'drug_used',\n",
       " 'experimentenddate',\n",
       " 'experimentstartdate',\n",
       " 'noofhourspassedatfirstreaction',\n",
       " 'conclusion',\n",
       " 'sideeffectsonparticipant']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the columns in variable columns to remove the .annotations\n",
    "\n",
    "columns = new_trials_df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten df\n",
    "# address null values\n",
    "# rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in the case study description the name of clinician is described as head_clincian's name\n",
    "# and the role is called the assisting clinician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used|experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|   conclusion|observed_side_effect|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|                19|      Ontario|          Saul|      therapist|  Placebo|      1619827200000|        1617235200000|                            52|BP normalized|      rashes on neck|\n",
      "|                14|      Ontario|          Saul|          nurse| Naproxen|      1619827200000|        1617235200000|                            78|    Follow-up|                 N/A|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename columns takes withColumnsRenamed and the dictionary of oldname:new name\n",
    "new_column_names = {\n",
    "    'ageofparticipant': 'age_of_participant'\n",
    "    , 'branch': 'clinic_branch'\n",
    "    , 'name': 'head_clinician'\n",
    "    , 'role': 'assistants_role'\n",
    "    , 'experimentenddate': 'experiment_end_date'\n",
    "    , 'experimentstartdate': 'experiment_start_date'\n",
    "    , 'noofhourspassedatfirstreaction': 'hours_passed_at_first_reaction'\n",
    "    , 'sideeffectsonparticipant': 'observed_side_effect'\n",
    "}\n",
    "new_trials_df = new_trials_df.withColumnsRenamed(new_column_names)\n",
    "new_trials_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix null values\n",
    "new_trials_df.describe().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value observed in 3 columns: assistants_role, hours_passed_at_first_reaction, conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill columns with null values\n",
    "# Putting 0 for hours might indicate immediate side effect after drug use, so no need filling\n",
    "\n",
    "new_trials_df = new_trials_df.na.fill({'conclusion': 'No entry', 'assistants_role': 'No entry'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age_of_participant: long (nullable = true)\n",
      " |-- clinic_branch: string (nullable = true)\n",
      " |-- head_clinician: string (nullable = true)\n",
      " |-- assistants_role: string (nullable = false)\n",
      " |-- drug_used: string (nullable = true)\n",
      " |-- experiment_end_date: string (nullable = true)\n",
      " |-- experiment_start_date: string (nullable = true)\n",
      " |-- hours_passed_at_first_reaction: long (nullable = true)\n",
      " |-- conclusion: string (nullable = false)\n",
      " |-- observed_side_effect: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+----------+--------------------+\n",
      "|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used|experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|conclusion|observed_side_effect|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+----------+--------------------+\n",
      "|                 0|            0|             0|              0|        0|                  0|                    0|                            73|         0|                   0|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.select([count(when(col(a).isNull() | isnan(col(a)) | col(a).isin('', 'null', None), a)).alias(a) for a in new_trials_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation steps\n",
    "##### experiment start and end date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age_of_participant: long (nullable = true)\n",
      " |-- clinic_branch: string (nullable = true)\n",
      " |-- head_clinician: string (nullable = true)\n",
      " |-- assistants_role: string (nullable = false)\n",
      " |-- drug_used: string (nullable = true)\n",
      " |-- experiment_end_date: string (nullable = true)\n",
      " |-- experiment_start_date: string (nullable = true)\n",
      " |-- hours_passed_at_first_reaction: long (nullable = true)\n",
      " |-- conclusion: string (nullable = false)\n",
      " |-- observed_side_effect: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The date format used here is a unix time stamp...counts number of seconds from Jan 1, 1970 to now\n",
    "new_trials_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/07 19:27:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+--------------+---------------+---------+--------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|summary|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used| experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|   conclusion|observed_side_effect|\n",
      "+-------+------------------+-------------+--------------+---------------+---------+--------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|  count|              3586|         3586|          3586|           3586|     3586|                3586|                 3586|                          3513|         3586|                3586|\n",
      "|   mean|17.507250418293363|         null|          null|           null|     null|1.618381578137200...| 1.615813671834913...|             44.89097637346997|         null|                null|\n",
      "| stddev|2.3066401927555233|         null|          null|           null|     null|2.3250351904618263E9| 2.2862846039555306E9|            24.540325490035848|         null|                null|\n",
      "|    min|                14|      Alberta|        Colins|       No entry| Naproxen|       1614643200000|        1612137600000|                             3|BP normalized|                 N/A|\n",
      "|    max|                21|       Quebec|       Windsor|      therapist|  Placebo|       1619827200000|        1617235200000|                            87|     No entry|      rashes on neck|\n",
      "+-------+------------------+-------------+--------------+---------------+---------+--------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as dtype\n",
    "# or from pyspark.sql import types as dtype\n",
    "import pyspark.sql.functions as fn\n",
    "# importing the whole pyspark.sql function module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date conversion from longtype to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type from string to Longtype(integer)\n",
    "# Divide by 1000\n",
    "# Convert from unix to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+-----------+\n",
      "|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used|experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|   conclusion|observed_side_effect|   start_ts|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+-----------+\n",
      "|                19|      Ontario|          Saul|      therapist|  Placebo|      1619827200000|        1617235200000|                            52|BP normalized|      rashes on neck|1.6198272E9|\n",
      "|                14|      Ontario|          Saul|          nurse| Naproxen|      1619827200000|        1617235200000|                            78|    Follow-up|                 N/A|1.6198272E9|\n",
      "|                17|      Ontario|          Saul|          nurse|  Placebo|      1619827200000|        1617235200000|                            14|    Follow-up|                 N/A|1.6198272E9|\n",
      "|                18|      Ontario|          Will|          nurse| Naproxen|      1619827200000|        1617235200000|                            14|BP normalized|                 N/A|1.6198272E9|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ----Coinversion steps\n",
    "\n",
    "# With column to create new columns\n",
    "# imported fn.col method on column of interest: experiment_end_date\n",
    "# Apply cast data conversion\n",
    "# pyspark.sql.types module as dtypes conversion applied on the column \n",
    "# /1000 cos we observed the data is more than 10 digits, probably in mili or micro secods, we need seconds\n",
    "# Data is in unix and unix is in seconds\n",
    "# So the whole datatype econversion is housed in our new column start_ts\n",
    "\n",
    "new_trials_df.withColumn('start_ts', fn.col('experiment_end_date').cast(dtype.LongType())/1000).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we Convert from unix to datetime, start date and end date\n",
    "# I first wrap fn.col---to the end in a bracket\n",
    "\n",
    "# new_trials_df.withColumn('start_ts', (fn.col('experiment_end_date').cast(dtype.LongType())/1000))\n",
    "# Then i'll introduce the function.from unix timestamp method, part of the function module imported as fn\n",
    "\n",
    "# new_trials_df.withColumn('start_ts', fn.from_unixtime(fn.col('experiment_end_date').cast(dtype.LongType())/1000))\n",
    "# We introduce our date format\n",
    "\n",
    "# new_trials_df.withColumn('start_ts', fn.from_unixtime(fn.col('experiment_end_date').cast(dtype.LongType())/1000),'yyyy-MM-dd HH:mm:ss.SSSS')\n",
    "# In the documentation it says time stamp conversion returns a string, so further conversion will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+--------------------+\n",
      "|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used|experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|   conclusion|observed_side_effect|            start_ts|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+--------------------+\n",
      "|                19|      Ontario|          Saul|      therapist|  Placebo|      1619827200000|        1617235200000|                            52|BP normalized|      rashes on neck|2021-05-01 03:00:...|\n",
      "|                14|      Ontario|          Saul|          nurse| Naproxen|      1619827200000|        1617235200000|                            78|    Follow-up|                 N/A|2021-05-01 03:00:...|\n",
      "|                17|      Ontario|          Saul|          nurse|  Placebo|      1619827200000|        1617235200000|                            14|    Follow-up|                 N/A|2021-05-01 03:00:...|\n",
      "|                18|      Ontario|          Will|          nurse| Naproxen|      1619827200000|        1617235200000|                            14|BP normalized|                 N/A|2021-05-01 03:00:...|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.withColumn('start_ts', fn.from_unixtime(fn.col('experiment_end_date').cast(dtype.LongType())/1000,'yyyy-MM-dd HH:mm:ss.SSSS')).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age_of_participant', 'bigint'),\n",
       " ('clinic_branch', 'string'),\n",
       " ('head_clinician', 'string'),\n",
       " ('assistants_role', 'string'),\n",
       " ('drug_used', 'string'),\n",
       " ('experiment_end_date', 'string'),\n",
       " ('experiment_start_date', 'string'),\n",
       " ('hours_passed_at_first_reaction', 'bigint'),\n",
       " ('conclusion', 'string'),\n",
       " ('observed_side_effect', 'string'),\n",
       " ('start_ts', 'string')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check our column to see the data type, it will return a string \n",
    "new_trials_df.withColumn('start_ts', fn.from_unixtime(fn.col('experiment_end_date').cast(dtype.LongType())/1000,'yyyy-MM-dd HH:mm:ss.SSSS')).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert from string to timestamp\n",
    "# You can always seperate your columns by using a backslash and continue on the next line\n",
    "# simply take the result of a line1, apply the backslash and use the withcolumn on the result of the first line as shown below\n",
    "# Doesn't have to be indented just for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnew_trials_df =new_trials_df.withColumn('experiment_start_date', fn.from_unixtime(col('experiment_start_date').cast(dtype.LongType())/1000, 'yyyy-MM-dd HH:mm:ss.SSSS'))\\\n",
    "    .withColumn('experiment_start_date', col('experiment_start_date').cast(dtype.TimestampType()))\\\n",
    "        .withColumn('experiment_end_date', fn.from_unixtime(col('experiment_end_date').cast(dtype.LongType())/1000, 'yyyy-MM-dd HH:mm:ss.SSSS'))\\\n",
    "            .withColumn('experiment_end_date', col('experiment_end_date').cast(dtype.TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unix to timestamp conversion # my code\n",
    "# If you import the entire function module as fn use fn.col, fn.count\n",
    "# If specific module is imported you can use col, count etc\n",
    "df = new_trials_df.withColumn('start_date', fn.unix_timestamp(fn.col('experiment_start_date').cast(dtype.LongType())/1000,'yyyy-MM-dd HH:mm:ss.SSSS'))\\\n",
    "    .withColumn('start_date', fn.col('start_date').cast(dtype.TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition by drug type for easy accessibility\n",
    "# order by conclusion and sideeffect for easy readability/analysis\n",
    "# Clinicians want to understand what they are reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|age_of_participant|clinic_branch|head_clinician|assistants_role|drug_used|experiment_end_date|experiment_start_date|hours_passed_at_first_reaction|   conclusion|observed_side_effect|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "|                19|      Ontario|          Saul|      therapist|  Placebo|2021-05-01 03:00:00|  2021-04-01 03:00:00|                            52|BP normalized|      rashes on neck|\n",
      "|                14|      Ontario|          Saul|          nurse| Naproxen|2021-05-01 03:00:00|  2021-04-01 03:00:00|                            78|    Follow-up|                 N/A|\n",
      "|                17|      Ontario|          Saul|          nurse|  Placebo|2021-05-01 03:00:00|  2021-04-01 03:00:00|                            14|    Follow-up|                 N/A|\n",
      "|                18|      Ontario|          Will|          nurse| Naproxen|2021-05-01 03:00:00|  2021-04-01 03:00:00|                            14|BP normalized|                 N/A|\n",
      "+------------------+-------------+--------------+---------------+---------+-------------------+---------------------+------------------------------+-------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml engineers want the data to be saved in an easily retrievable format, so we do \n",
    "#### also want data partitioned by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_of_participant',\n",
       " 'clinic_branch',\n",
       " 'head_clinician',\n",
       " 'assistants_role',\n",
       " 'drug_used',\n",
       " 'experiment_end_date',\n",
       " 'experiment_start_date',\n",
       " 'hours_passed_at_first_reaction',\n",
       " 'conclusion',\n",
       " 'observed_side_effect']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordered columns and pick out columns of interest for the clinicians\n",
    "# Partition by so the clinicians can view the two trial drugs trials in different csv for easy accesibility\n",
    "# Partition by is like using .loc to filter two different DFS and -to_csv into 2 csvs\n",
    "new_trials_df = new_trials_df.select(['experiment_start_date', 'experiment_end_date', 'clinic_branch', 'drug_used', 'head_clinician', 'assistants_role', 'age_of_participant', 'hours_passed_at_first_reaction', 'conclusion', 'observed_side_effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+-------------+--------------------+\n",
      "|experiment_start_date|experiment_end_date|clinic_branch|drug_used|head_clinician|assistants_role|age_of_participant|hours_passed_at_first_reaction|   conclusion|observed_side_effect|\n",
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+-------------+--------------------+\n",
      "|  2021-04-01 03:00:00|2021-05-01 03:00:00|      Ontario|  Placebo|          Saul|      therapist|                19|                            52|BP normalized|      rashes on neck|\n",
      "|  2021-04-01 03:00:00|2021-05-01 03:00:00|      Ontario| Naproxen|          Saul|          nurse|                14|                            78|    Follow-up|                 N/A|\n",
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trials_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data by experiment_start_date, header = True, partition into 2 csvs by drug used, mode of writing \n",
    "# is overwrite and folder where partitioned file saved is clinician folder\n",
    "new_trials_df.sort('experiment_start_date').write.option('header', True)\\\n",
    "    .partitionBy(['drug_used'])\\\n",
    "    .mode('overwrite')\\\n",
    "    .csv('clinician')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Month from TimeStamp for ml engineers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column month and year added # and this is not saving to a csv\n",
    "# parquet is a different file format unlike csvs, saves in column oriented rather than rows in csv\n",
    "ml_trial_results = new_trials_df.withColumn('exp_start_month', fn.month(fn.col('experiment_start_date')))\\\n",
    "    .withColumn('exp_start_year', fn.year(col('experiment_start_date'))).sort('experiment_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+----------+--------------------+---------------+--------------+\n",
      "|experiment_start_date|experiment_end_date|clinic_branch|drug_used|head_clinician|assistants_role|age_of_participant|hours_passed_at_first_reaction|conclusion|observed_side_effect|exp_start_month|exp_start_year|\n",
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+----------+--------------------+---------------+--------------+\n",
      "|  2021-02-01 02:00:00|2021-03-02 02:00:00|      Alberta| Naproxen|       Johnson|          nurse|                20|                            45| Follow-up|      rashes on neck|              2|          2021|\n",
      "|  2021-02-01 02:00:00|2021-03-02 02:00:00|      Alberta| Naproxen|        Greene|      therapist|                16|                            75| No effect|           headaches|              2|          2021|\n",
      "|  2021-02-01 02:00:00|2021-03-02 02:00:00|      Alberta| Naproxen|       Johnson|      therapist|                14|                            31| No effect|       arms and feet|              2|          2021|\n",
      "|  2021-02-01 02:00:00|2021-03-02 02:00:00|      Alberta|  Placebo|        Greene|      therapist|                15|                            29| Follow-up|         light fever|              2|          2021|\n",
      "+---------------------+-------------------+-------------+---------+--------------+---------------+------------------+------------------------------+----------+--------------------+---------------+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_trial_results.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_trials_df.withColumn('start_month', fn.month('experiment_start_date'))\\\n",
    ".sort('experiment_start_date').write.partitionBy('start_month')\\\n",
    "    .mode('overwrite').format('parquet').save('ml_engineers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_trial_results.write.option('header', True)\\\n",
    "    .partitionBy(['exp_start_month', 'drug_used'])\\\n",
    "        .mode('overwrite')\\\n",
    "            .parquet('ml_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
